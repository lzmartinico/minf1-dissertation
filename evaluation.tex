As with all software artefacts that have a user facing component, testing can be lead both on a technical level and on a usability level. Since the chatbot infrastructure contains many different components, it will be necessary to conduct some testing on the robustness of each.
\section{Testing}
Throughout the whole implementation, particular care was taken to follow software engineering best practices. Because JavaScript is a dynamically typed language, we lack a compiler's check for code correctness. As a consequence, we have to run code to find out if it works. To avoid deploying a broken commit to the server, we wrote a git pre-commit hook to test if the program doesn't crash immediately, and to pass a linter to catch any syntax error in the code:
\begin{lstlisting}
npm start > /dev/null &
sleep 5
if ``eslint *.js`` && [[ -n `pidof -k node` ]] ; then
    echo "Pass linter and npm doesn't crash"
    exit 0
else
    pkill node
    exit 1
fi
\end{lstlisting}
While this was a good tool to statically catch errors, some bugs would only emerge through dynamic testing. While the \textit{testmybot} unit test library \cite{} looked like a promising solution for establishing a routine of test-driven development, it soon was evident that the Facebook hooks for the underlying Botium library \cite{} are still not mature enough to be used in production. Therefore, rather than having a collection of sample conversations we could feed \textit{testmybot} to determine whether any new code change would break any of the responses we had been getting before, we had to resort to manually testing each new feature, by messaging the chatbot from a personal Facebook account, repeating the same script for each different functionality we had previously implemented. Most debugging information was printed to the Heroku server logs through the \textit{console.log} JavaScript function.
\section{Evaluation}
For our evaluation, we ran an experiment giving out the chatbot to 11 university students, all within ages of 20 to 25 and at least moderately physically active, to use for a week. As a control group, another 9 university students were prescribed to use the MyFitnessPal app for the same duration. All users were recruited through Facebook chat or in person, and all were given the OK to start the evaluation on the same day after having read and signed a consent form describing the experiment and the tester's role in it. In retrospect, having a more gradual rollout might have helped with spotting the first bugs sooner, and giving us a chance to fix the underlying issues without compromising the platform for every other user. As it was, while we identified several issues and features that would have been immediately easy to add, we did not push most of the modification to avoid breaking existing users' workflows. Unfortunately Facebook does not allow to have a separate testing and production environments until the application goes through a first review process, which we couldn't afford to spend time going through.
\subsection{Record keeping}
Since this was our first usage of the chatbot outside our own testing, we expected to encounter a variety of bugs and phrasings that it had never encountered from us. We set up a detailed logging function for all error case, printing the user ID as well so as to be able to reconstruct the causes at a later stage. We could also access a complete record of all communication through the Facebook app console, as well as having a list of intents identified and how the parameters were matched from the Dialogflow agent. While having this much access gave us some great insight into what might be affecting faulty behaviours, it was also concerning how we could read the conversations in their entirety, and while Dialogflow allows to deactivate the logging, there was no way of doing that through Facebook. And even if there was, it would be trivially easy to still log everything through the server.


\subsection{Experiment description - survey, in person interview}
To initiate the experiment, the chatbot users' Facebook profiles were added as testers through the Facebook developer console. They were then sent a link to the chatbot's Facebook page, where they could press a clearly visible button to start chatting. This would open a chat window, where they had the option of pressing a button to get started before being taken through their first conversation. Users were given no indication on how to precede, except for the chatbot's introductory message. Over the course of the evaluation, users sent us some questions (never through the chatbot) on what they could do with it. \\
The MyFitnessPal testers were asked to give feedback a week after the evaluation started; the bot testers were sent feedback forms after 9 days.
The surveys sent to both testers were built using the Google Forms online tool. Most questions were similar to both questionnaires, with some variation when it came to input methods and displays dependent on the app. In compliance with the consent form, none of the questions were made compulsory, and the survey was made anonymous.
The questionnaire asked some background information on the participant, to establish levels of fitness and computer literacy, thoughts on nutrition and previous dietary and food tracking histories.
Testers were then asked their opinion on the usability, utility, pleasantness of the entire platform they were evaluating, as well as for each specific functionality, and if they had any feedback on things they would have liked to see. Some answers were multiple choices, checkboxes or Likert scales, but most were open text input to allow the participant to give a full explanation of the reasoning behind their answer
\subsubsection{Survey Response}
7 participants responded to the My Fitness Pal survey within the first day, and 9 to the chatbot specific survey. While some questions were answered by all the participants who took the survey, none of the open ended questions were answered by all, sometimes with around half the respondents ignoring one question (??Verify??). \\
Participants seemed to be distributed similarly across the two trials, with chatbot users being slightly more proficient with computers, as well as being more aware of their fitness levels. Similar splits were evident in the proportions of participants who had died before, with around three quarters of participants citing a good current health or scepticism with established diet, and some chatbot users using laziness as a motivation. The minority of users who had dieted chose to do so because of environmental, athletic or health-related issues, but did not maintain dieting after reaching their goals, or because of commitment issues. Among both groups, about half the participants consistently had 3 meals per day, with some having a variable number of meals and no participants consuming less than two; our chatbot users however in general snacked less than My Fitness Pal users (there's a possibility that these answers might have been influenced by the experiment, even if participants were encouraged to think about their behaviour before; the fact that My Fitness Pal presents snack as a distinctly separate category, and the chatbot doesn't, might have affected responses to this question). \\
About half of the participants reported having tracked their diet before, either keeping a food diary, memorizing their meal, or, the majority of respondents, using My Fitness Pal, and the majority of previous trackers also kept a record of their snacks. \\
For unclear reasons, more than half the respondents skipped the section about their dietary makeup, but for who did fill it in, definitions of ``balanced diet'' varied significantly: while a majority named a variation of having a correct proportion of Protein, Carbohydrates and Fats, with some allowing for vitamins and minerals as well, others named calories as a main concern, reducing some unhealthy food groups and increasing others, or avoiding stressing about their diet and making sure to have what made them feel good. Only half of the respondents consider their diet to be balanced, including all those who planned their meals in advanced, and most respondents tend to cook their own meals, eat out or do both things in equal measure. \\
My Fitness Pal user found the app on average more useful than chatbot user, although the latter was rated as generally more pleasant to use. The food diary, the macronutrient breakdown graph and the remaining calorie counter were all generally considered clear and useful, with the graph being the most pleasant feedback. For input, the majority of users preferred scanning the barcode of the meal they were having, although for some the kind of food they were eating was a factor, and people who tended to cook their own food preferred text entries. All users had some issues with finding the food they wanted using text entry, but no one complained about the method being too slow; barcode scanning seemed to perform better, with only some users reporting difficulties identifying a barcode or matching the correct item in the database. By contrast, chatbot users generally found the feedback useless, or insufficient. Chatting was highly preferred as an input method, although several participants didn't find it understood their queries well enough, and some were annoyed by the prompts for size. Some users who took pictures for input found it wasn't accurate, but the larger problem for the feature seemed to be people who weren't aware of the functionality. \\
Retention rates were much higher for My Fitness Pal users, with the largest missed meals estimated to be 5, and some user logging all their meals; chatbot users, instead, were much less active, with one person logging almost every meal, and everyone else estimating having missed between 5 and 20. In both cases, the leading cause of missing a meal log was lack of time or forgetfulness, with some chatbot users finding input methods cumbersome or lack of interest because the feedback didn't seem useful. As a consequence, almost all chatbot testers did not log their meals on several days. Half of the users report having received a reminder the day after, with the other saying they didn't (which might be explainable by the fact that, while everyone received a reminder, it wasn't necessarily after a day of inactivity). The reminders were generally found to be useful, and mostly made the users log their food on the day, and one user even expressed a desire to receive more frequent prompts to avoid forgetting more meals. My Fitness Pal also provided a reminder functionality, but it's off by default. All users who turned it on got a reminder, but it didn't make them use the app after. \\
One stark difference in response between chatbot and app user was on preference between noting their food records with absolute measurement (number of portions or unit of measurement plus numerical value). My Fitness Pal users overwhelmingly declared a preference for absolute value metrics, because of the need to calculate precise calorie counts that the app provides, and as a more reliable comparison method to standard recommended portion sizes. The majority of chatbot users instead indicated a preference for relative values, because it's easier not to have to constantly measure portions. \\
Despite the fact that the utility of a food diary comes from the ability to look back on previous meals, only a third of the chatbot users, and just over half the app users took advantage of this feature at a later date, and those who did reported the information presented to them to be accurate, but unhelpful; in fact, about half of the chatbot users and two thirds of the app user don't think using the meal log has given them a better idea of how they eat. \\
Overall, most participants did not think that logging their food had helped them to eat better, although for many users that was because they already are happy with their diet. Those that registered a positive impact mentioned that having a better oversight on their food trends did prove helpful for them, and My Fitness Pal user specified sugar tracking and suggested recipes as useful features, although some comments also pointed out that the paid version of the app could have been more useful. However, $\frac{2}{3}$ of chatbot users found that they had become more ``mindful'' about their diet by using the chatbot, as opposed to less than half of the My Fitness Pal users. \\
Expectations for the chatbot were high for some users who were hoping for \textit{[a] good AI} which would be talkative and give them active reminders and regular feedback; some were just looking for a more convenient way to log their food; but most participants did not expect much from it. Needless to say, the former group were disappointed by our implementation, with the natural language parsing of quantities, repetitive replies and image recognition capabilities being particularly frustrating. At the same time, users appreciated the ability to choose input method, and some found the chatbot's personality less annoying than they expected. My Fitness Pal tester also were expecting ease of use, a complete database, and a tool that would prompt small change in their behaviours by highlighting trends that were needed to be changed. Most of these were met by participants, although the majority of American commercial products in the database was deemed a problem. \\
When asked if they would continue to log their meals after the evaluation period, participants on both platforms were mostly uninterested, either because they didn't find it useful enough, or because logging took too much time, and in the case of the chatbot, they perceived the product development as not being ready enough for regular usage. However, some users who seemed to have benefited from its usage were willing to continue using, or at least consider it in case of future more rigorous dieting, and one My Fitness Pal user was convinced to resume their paper food diary. \\
About half the My Fitness Pal users enabled fitness tracking functions, which seemed generally well received, although there were some concerns to how accurate their estimations were, and how useful it is to simply subtract exercise from calorie intake from a nutritional standpoint. Participants who did not use the feature were potentially interested, but the interface wasn't easy to understand, and there were perceived barriers to entry such as downloading a separate companion app or owning a smartwatch to better track calorie expenditure.\\
Testers of the app suggested they would have liked to have dedicated fruit and vegetable counters, automatic exercise calorie calculations and personalized recipe suggestions based on a specific ingredient or past meals and goals. For the chatbot, suggestions included pointing out a food's recommended amount, more reminders, especially around 5-a-day tracking, retroactively adding past meals, adding more variation to the automatic replies to make them less boring, and better onboarding functionality.
As part of the survey participants were  also asked if they thought that the information they were uploading was being kept safe, and if they thought it was an important concern. Most participants were actually concerned about their dietary records being exposed, with some particularly concerned with being judged because of their diet, while others didn't think food records were a particularly sensitive topic, and anonymising dietary data could be used to benefit medical research organisations. Users of the chatbot generally considered their information to be secured, and while one participant specified ``I know its developer takes security seriously'', another identified that platform issues were a problem ``I mean it's on facebook so not really.''. On the other hand, My Fitness Pal users were more concerned or unsure whether their information was safe or not, and with good reason: two days after the study completed, the app's parent company \textit{Under Armour} publicly announced it had been a victim in one of the largest ever leaks of user personal information \cite{underarmour}.