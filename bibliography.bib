Automatically generated by Mendeley Desktop 1.17.11
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@misc{JavierCouto,
author = {{Javier Couto}},
title = {{Building a Chatbot: analysis {\&} limitations of modern platforms - Tryolabs Blog}},
url = {https://tryolabs.com/blog/2017/01/25/building-a-chatbot-analysis--limitations-of-modern-platforms/},
urldate = {2017-10-29},
year = {2017}
}
@article{Ahmad2016,
abstract = {? 2016 ACM.This paper presents an integrated dietary assessment system based on food image analysis that uses mobile devices or smartphones. We describe two components of our integrated system: a mobile application and an image-based food nutrient database that is connected to the mobile application. An easy-to-use mobile application user interface is described that was designed based on user preferences as well as the requirements of the image analysis methods. The user interface is validated by user feedback collected from several studies. Food nutrient and image databases are also described which facilitates image-based dietary assessment and enable dietitians and other healthcare professionals to monitor patients dietary intake in real-time. The system has been tested and validated in several user studies involving more than 500 users who took more than 60,000 food images under controlled and community-dwelling conditions.},
author = {Ahmad, Ziad and Bosch, Marc and Khanna, Nitin and Kerr, Deborah A. and Boushey, Carol J. and Zhu, Fengqing and Delp, Edward J.},
doi = {10.1145/2986035.2986038},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/p53-ahmad.pdf:pdf},
isbn = {9781450345200},
journal = {Proceedings of the 2nd International Workshop on Multimedia Assisted Dietary Management - MADiMa '16},
keywords = {dietary assessment,evidence-based design,food image database,mobile food record,user interface},
pages = {53--62},
pmid = {28691119},
title = {{A Mobile Food Record For Integrated Dietary Assessment}},
url = {http://dl.acm.org/citation.cfm?doid=2986035.2986038},
year = {2016}
}
@article{Casperson2015,
abstract = {BACKGROUND Mobile technologies are emerging as valuable tools to collect and assess dietary intake. Adolescents readily accept and adopt new technologies; thus, a food record app (FRapp) may be a useful tool to better understand adolescents' dietary intake and eating patterns. OBJECTIVE We sought to determine the amenability of adolescents, in a free-living environment with minimal parental input, to use the FRapp to record their dietary intake. METHODS Eighteen community-dwelling adolescents (11-14 years) received detailed instructions to record their dietary intake for 3-7 days using the FRapp. Participants were instructed to capture before and after images of all foods and beverages consumed and to include a fiducial marker in the image. Participants were also asked to provide text descriptors including amount and type of all foods and beverages consumed. RESULTS Eight of 18 participants were able to follow all instructions: included pre- and post-meal images, a fiducial marker, and a text descriptor and collected diet records on 2 weekdays and 1 weekend day. Dietary intake was recorded on average for 3.2 (SD 1.3 days; 68{\%} weekdays and 32{\%} weekend days) with an average of 2.2 (SD 1.1) eating events per day per participant. A total of 143 eating events were recorded, of which 109 had at least one associated image and 34 were recorded with text only. Of the 109 eating events with images, 66 included all foods, beverages and a fiducial marker and 44 included both a pre- and post-meal image. Text was included with 78 of the captured images. Of the meals recorded, 36, 33, 35, and 39 were breakfasts, lunches, dinners, and snacks, respectively. CONCLUSIONS These data suggest that mobile devices equipped with an app to record dietary intake will be used by adolescents in a free-living environment; however, a minority of participants followed all directions. User-friendly mobile food record apps may increase participant amenability, increasing our understanding of adolescent dietary intake and eating patterns. To improve data collection, the FRapp should deliver prompts for tasks, such as capturing images before and after each eating event, including the fiducial marker in the image, providing complete and accurate text information, and ensuring all eating events are recorded and should be customizable to individuals and to different situations. TRIAL REGISTRATION Clinicaltrials.gov NCT01803997. http://clinicaltrials.gov/ct2/show/NCT01803997 (Archived at: http://www.webcitation.org/6WiV1vxoR).},
author = {Casperson, Shanon L and Sieling, Jared and Moon, Jon and Johnson, LuAnn and Roemmich, James N and Whigham, Leah},
doi = {10.2196/mhealth.3324},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/Papers/Health/Caperson, Sieling et al.pdf:pdf},
isbn = {2291-5222},
issn = {2291-5222},
journal = {JMIR mHealth and uHealth},
number = {1},
pages = {e30},
pmid = {25775506},
title = {{A Mobile Phone Food Record App to Digitally Capture Dietary Intake for Adolescents in a Free-Living Environment: Usability Study}},
url = {http://mhealth.jmir.org/2015/1/e30/},
volume = {3},
year = {2015}
}
@article{Werner-Seidler2017,
abstract = {BACKGROUND Sleep disturbances are common in young people and have consequences for academic, social, emotional, and behavioral development. The most effective treatment is cognitive behavioral therapy for insomnia (CBT-I), with evidence suggesting that it is efficacious even when delivered digitally. OBJECTIVE There are no commercially available digitally delivered CBT-I programs for use by young people. The aim of this project was to develop a smartphone app that delivers CBT-I to young people to improve sleep. METHODS To inform the development of the app, young people (N=21) aged between 12 and 16 years attended one of the 3 focus groups (each with 4-10 participants). These focus groups were conducted at different stages of the development process such that the process could be iterative. Participants were asked the reasons why they might use an app to help them sleep, the kinds of features or functions that they would like to see in such an app, and any concerns they may have in using the app. Data were analyzed using a thematic analysis approach. Of the issues discussed by the participants, the researchers selected themes associated with content, functionality, and accessibility and user experience to examine, as these were most informative for the app design process. RESULTS In terms of content, young people were interested in receiving information about recommended sleep guidelines and personalized information for their age group. They reported that keeping a sleep diary was acceptable, but they should be able to complete it flexibly, in their own time. They reported mixed views about the use of the phone's accelerometer. Young people felt that the functionality of the app should include elements of game playing if they were to remain engaged with the app. Flexibility of use and personalized features were also desirable, and there were mixed views about the schedule of notifications and reminders. Participants reported that for the app to be accessible and usable, it should be from a trusted developer, have engaging aesthetics, have a layout that is easy to navigate, not rely on Internet coverage, and preferably be free. Participants felt that being able to conceal the purpose of the app from peers was an advantage and were willing to provide personal information to use the app if the purpose and use of that information was made clear. Overall, participants endorsed the use of the app for sleep problems among their age group and reported motivation to use it. CONCLUSIONS The Sleep Ninja is a fully-automated app that delivers CBT-I to young people, incorporating the features and information that young people reported they would expect from this app. A pilot study testing the feasibility, acceptability, and efficacy of the Sleep Ninja is now underway.},
author = {Werner-Seidler, Aliza and O'Dea, Bridianne and Shand, Fiona and Johnston, Lara and Frayne, Anna and Fogarty, Andrea S and Christensen, Helen},
doi = {10.2196/mental.7614},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/fc-xsltGalley-7614-137884-13-PB.pdf:pdf},
issn = {2368-7959},
journal = {JMIR Mental Health},
keywords = {2017,3,adolescence,cognitive behavioral therapy,depression,e28,http,insomnia,jmir,mental,org,sleep,smartphone},
number = {3},
pages = {e28},
pmid = {28754651},
title = {{A Smartphone App for Adolescents With Sleep Disturbance: Development of the Sleep Ninja}},
url = {http://mental.jmir.org/2017/3/e28/},
volume = {4},
year = {2017}
}
@article{Boushey2016,
abstract = {{\textless}p{\textgreater}For nutrition practitioners and researchers, assessing dietary intake of children and adults with a high level of accuracy continues to be a challenge. Developments in mobile technologies have created a role for images in the assessment of dietary intake. The objective of this review was to examine peer-reviewed published papers covering development, evaluation and/or validation of image-assisted or image-based dietary assessment methods from December 2013 to January 2016. Images taken with handheld devices or wearable cameras have been used to assist traditional dietary assessment methods for portion size estimations made by dietitians (image-assisted methods). Image-assisted approaches can supplement either dietary records or 24-h dietary recalls. In recent years, image-based approaches integrating application technology for mobile devices have been developed (image-based methods). Image-based approaches aim at capturing all eating occasions by images as the primary record of dietary intake, and therefore follow the methodology of food records. The present paper reviews several image-assisted and image-based methods, their benefits and challenges; followed by details on an image-based mobile food record. Mobile technology offers a wide range of feasible options for dietary assessment, which are easier to incorporate into daily routines. The presented studies illustrate that image-assisted methods can improve the accuracy of conventional dietary assessment methods by adding eating occasion detail via pictures captured by an individual (dynamic images). All of the studies reduced underreporting with the help of images compared with results with traditional assessment methods. Studies with larger sample sizes are needed to better delineate attributes with regards to age of user, degree of error and cost.{\textless}/p{\textgreater}},
author = {Boushey, C. J. and Spoden, M. and Zhu, F. M. and Delp, E. J. and Kerr, D. A.},
doi = {10.1017/S0029665116002913},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/new{\_}mobile{\_}methods{\_}for{\_}dietary{\_}assessment{\_}review{\_}of{\_}imageassisted{\_}and{\_}imagebased{\_}dietary{\_}assessment{\_}methods.pdf:pdf},
isbn = {0029665116},
issn = {0029-6651},
journal = {Proceedings of the Nutrition Society},
number = {December 2016},
pages = {1--12},
pmid = {27938425},
title = {{New mobile methods for dietary assessment: review of image-assisted and image-based dietary assessment methods}},
url = {http://www.journals.cambridge.org/abstract{\_}S0029665116002913},
year = {2016}
}
@article{McTear2016,
abstract = {Presents a comprehensive overview of the various technologies that underlie conversational user interfaces Combines descriptions of the technologies with a guide to various toolkits and software that enable readers to implement and test their own solutions Provides a series of worked examples so readers can develop and implement different aspects of the technologies.},
author = {McTear, Michael and Callejas, Zoraida and Griol, David},
doi = {10.1007/978-3-319-32967-3},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/10.1007-978-3-319-32967-3{\_}2.pdf:pdf},
isbn = {9783319329673},
journal = {The Conversational Interface: Talking to Smart Devices},
pages = {1--422},
title = {{The conversational interface: Talking to smart devices}},
year = {2016}
}
@article{Boushey2016a,
abstract = {{\textless}p{\textgreater}For nutrition practitioners and researchers, assessing dietary intake of children and adults with a high level of accuracy continues to be a challenge. Developments in mobile technologies have created a role for images in the assessment of dietary intake. The objective of this review was to examine peer-reviewed published papers covering development, evaluation and/or validation of image-assisted or image-based dietary assessment methods from December 2013 to January 2016. Images taken with handheld devices or wearable cameras have been used to assist traditional dietary assessment methods for portion size estimations made by dietitians (image-assisted methods). Image-assisted approaches can supplement either dietary records or 24-h dietary recalls. In recent years, image-based approaches integrating application technology for mobile devices have been developed (image-based methods). Image-based approaches aim at capturing all eating occasions by images as the primary record of dietary intake, and therefore follow the methodology of food records. The present paper reviews several image-assisted and image-based methods, their benefits and challenges; followed by details on an image-based mobile food record. Mobile technology offers a wide range of feasible options for dietary assessment, which are easier to incorporate into daily routines. The presented studies illustrate that image-assisted methods can improve the accuracy of conventional dietary assessment methods by adding eating occasion detail via pictures captured by an individual (dynamic images). All of the studies reduced underreporting with the help of images compared with results with traditional assessment methods. Studies with larger sample sizes are needed to better delineate attributes with regards to age of user, degree of error and cost.{\textless}/p{\textgreater}},
author = {Boushey, C. J. and Spoden, M. and Zhu, F. M. and Delp, E. J. and Kerr, D. A.},
doi = {10.1017/S0029665116002913},
isbn = {0029665116},
issn = {0029-6651},
journal = {Proceedings of the Nutrition Society},
number = {December 2016},
pages = {1--12},
pmid = {27938425},
title = {{New mobile methods for dietary assessment: review of image-assisted and image-based dietary assessment methods}},
url = {http://www.journals.cambridge.org/abstract{\_}S0029665116002913},
year = {2016}
}
@article{Dehais2016,
author = {Dehais, Joachim and Anthimopoulos, Marios and Mougiakakou, Stavroula},
doi = {10.1145/2986035.2986047},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/Papers/Dehais, Anthimopoulos, Mougiakakou.pdf:pdf},
isbn = {9781450345200},
journal = {Proceedings of the 2nd International Workshop on Multimedia Assisted Dietary Management - MADiMa '16},
pages = {23--28},
title = {{Food Image Segmentation for Dietary Assessment}},
url = {http://dl.acm.org/citation.cfm?doid=2986035.2986047},
year = {2016}
}
@article{Pistorius2017,
abstract = {DeltaHedron Innovation Insight is a regular newsletter exploring aspects of the technological future and technological innovation, with a specific focus on the strategic business opportunities, threats, risks and impact presented by emerging technologies and the dynamics of technological change Executive summary • A number of recent developments in emerging digital health technologies are considered in this newsletter. Telehealth and mHealth enable patients to access healthcare remotely. The resulting 'empowerment of the patient' is disrupting the industry and radically transforming the delivery, scope, quality and cost of, as well as access to, healthcare in developed and developing countries. Digital health technologies are dynamic with rapid changes in their performance, costs, applications and user bases. The industry structure is changing as are cost curves, business models and the power and influence patterns amongst role players. Significant new value is being created and new outcomes enabled. • Emerging digital health technologies should be high on the radar of companies as they assess strategic business opportunities, threats and risks. Traditional healthcare providers (including professional practitioners, hospitals and clinics), health insurers, funders, healthcare systems and producers of health technology products as well as new entrants and new types of entrants in the healthcare sector need to be aware of the disruptive shifts in the industry. Opportunities also abound for role players in other sectors that may, at first blush, not seem to be related or affected. Conversely, emerging digital technologies may also present risks and threats to role players in seemingly unrelated sectors. A strategic opportunity/threat/risk review is helpful to assess a specific company's or industry sector's technological innovation-related opportunities and vulnerabilities vis-{\`{a}}-vis emerging digital health technologies. • The ability to communicate wirelessly via 3G and 4G (and soon 5G) as well as through routed wifi networks, position mobile devices (such as smart phones or smart watches) as ideal mHealth platforms. Many sensors and features that are useful in mHealth applications are already imbedded in the mobile device itself, including clocks, flash lights, microphones, cameras, geo-position sensors (GPS) and accelerometers. Additional sensors can be integrated into a peripheral device (such as a scale or blood pressure monitor) connected to and communicating with the mobile device, typically through bluetooth. Recent reports mention mobile and portable sensors that can measure weight and body temperature, blood pressure and sugar levels, oxygen level and blood oxygenation, heart rate, rhythms and conditions, speech patterns, spectrometry, spirometry, dental parameters, cells structures of food, taste, blood alcohol content, sperm count, activity level and sleep quality; as well as ambient parameters such as pollution and noise. • mHealth, either locally through an app in the mobile device or through remote access, provides the capability to interpret the inputs from these sensors and then to identify and treat a range of clinical conditions. This information can be made available directly to the patient, often in real-time. Diabetes, hypertension, heart conditions, cancer, skin diseases, seizures and epilepsy, pain management, male fertility, mental health and home care are amongst many conditions recent reported on. Related reports also cover a range of wellness and fitness issues (including fatigue and substance abuse, which have important applications in industrial settings). DeltaHedron Innovation Insight Developments in emerging digital health technologies No 1.1/17 April 2017 2 {\textcopyright} DeltaHedron 2017 • The disruptive impacts of emerging technologies often come from completely different industries than those they disrupt. The impact of a specific emerging technology can be enabled, enhanced and amplified (or alternatively hindered) by its interaction with other technologies, specifically also other emerging technologies. Recent reports refer to applications of artificial intelligence and machine learning, virtual reality, imaging, internet of things, robotics, chatbots, 3-D printing and drones interacting with digital health technologies. • Health information is the lifeblood of digital health technologies, and significant effort is being directed towards capturing, communicating, storing, sharing, protecting, processing, interpreting and displaying the information. It is one the most significant drivers for strategic business opportunities and threats presented by emerging digital health technologies. The focus is on actionable information and decision support to patients, healthcare providers and other role players – everywhere, any time and in real-time. Recent reports focus on the use of remote patient monitoring (RPM), big data and health analytics, data security (including blockchain), patient generated health data (PGHD) and electronic health records (EHR). Interoperability of datasets remains problematic. • Many challenges and uncertainties remain to be resolved for emerging digital health technologies, as would be expected of any emerging technology. Apart from the technical and clinical challenges, issues pertaining to ethics, liability, data security, policies and regulation need to be addressed. The vexing problem of business models and the 'difficulties of making money' from telehealth and mHealth are important, as are the related issues of funding models and reimbursement of claims for digital health provision. These difficulties are complicated by the fact that traditional business models don't work very well in a platform-enabled, digital health world driven by new types of information and empowered patients. • As digital health, telehealth and mHealth become more ubiquitous, the nature of health-related jobs will necessarily also change. Inevitably new types of roles will emerge and current roles may disappear. One can, for example, imagine new and different roles for healthcare providers such as doctors, nurses and therapists. It is also necessary to consider how curricula for training healthcare professionals in the new digital health world should be developed and proactively adopted by universities and other education and training institutions. Accreditation bodies that regulate health qualifications and register professionals should also address this matter. It is important to ensure that the next generation of healthcare providers as well as the current practioners are prepared, able and willing to leverage the benefits of the new technologies. This will require not only an understanding of the new technologies and the skills to use them, but also a deeper understanding of the notion of the 'empowered patient' and how that will affect the relationships between patients and healthcare providers. Continual professional training in digital health technologies for practising professionals should be a high priority.},
author = {Pistorius, Calie},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/DeltaHedron{\_}Innovation-Insight{\_}Digital-health{\_}No-1.1-17{\_}-April-2017.pdf:pdf},
keywords = {Innovation,digital,disruptive,emerging,health,mhealth,technology,telehealth},
number = {1},
title = {{Developments in emerging digital health technologies}},
year = {2017}
}
@article{Kowatsch,
author = {Kowatsch, Tobias and Ni{\ss}en, Marcia and Shih, Chen-hsuan Iris and R{\"{u}}egger, Dominik and Filler, Andreas and K{\"{u}}nzler, Florian and Barata, Filipe and Haug, Severin and Brogle, Bj{\"{o}}rn and Heldt, Katrin and Gindrat, Pauline and Farpour-lambert, Nathalie and Allemand, Dagmar},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/2368{\_}Kowatsch et al 2017 - THCB PEACH Workshop.pdf:pdf},
keywords = {attachment bond,chatbot,conversational agent,counseling psychology,human-computer interaction,in-,terpersonal closeness},
number = {Iva 2017},
pages = {1--10},
title = {{Text-based Healthcare Chatbots Supporting Patient and Health Professional Teams : Preliminary Results of a Randomized Controlled Trial on Childhood Obesity}},
volume = {1}
}
@article{Myers2015,
abstract = {We present a system which can recognize the contents of your meal from a single image, and then predict its nu- tritional contents, such as calories. The simplest version assumes that the user is eating at a restaurant for which we know the menu. In this case, we can collect images offline to train a multi-label classifier. At run time, we apply the classifier (running on your phone) to predict which foods are present in your meal, and we lookup the corresponding nutritional facts. We apply this method to a new dataset of images from 23 different restaurants, using a CNN-based classifier, significantly outperforming previous work. The more challenging setting works outside of restaurants. In this case, we need to estimate the size of the foods, as well as their labels. This requires solving segmentation and depth / volume estimation from a single image. We present CNN-based approaches to these problems, with promising preliminary results. 1.},
author = {Myers, Austin and Johnston, Nick and Rathod, Vivek and Korattikara, Anoop and Gorban, Alex and Silberman, Nathan and Guadarrama, Sergio and Papandreou, George and Huang, Jonathan and Murphy, Kevin},
doi = {10.1109/ICCV.2015.146},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/44321.pdf:pdf},
isbn = {9781467383912},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
number = {December},
pages = {1233--1241},
title = {{Im2Calories: Towards an automated mobile vision food diary}},
volume = {2015 Inter},
year = {2015}
}
@book{Mao2005,
abstract = {Intelligent virtual agents are typically embedded in a social environment and must reason about social cause and effect. Social causal reasoning is qualitatively different from physical causal reasoning that underlies most current intelligent systems. Besides physical causality, the assessments of social cause emphasize epistemic variables including intentions, foreknowledge and perceived coercion. Modeling the process and inferences of social causality can enrich the believability and the cognitive capabilities of social intelligent agents. In this paper, we present a general computational model of social causality and responsibility, and empirically evaluate and compare the model with several other approaches.},
author = {Mao, Wenji and Gratch, Jonathan and Panayiotopoulos, Themis and Aylett, Ruth and Ballin, Daniel and Olivier, Patrick and Rist, Thomas},
booktitle = {Lecture Notes in Computer Science},
doi = {10.1007/11550617},
isbn = {978-3-540-28738-4},
issn = {0302-9743},
pages = {191--204},
title = {{Intelligent Virtual Agents}},
url = {http://www.springerlink.com/content/0ex3rjfnve8hwwh6/},
volume = {3661},
year = {2005}
}
@article{Ajayakumar2017,
abstract = {There are lot of treatments that are available for various diseases. No human can possibly know about all the medicines and the diseases. So, the problem is that there isn't any place where anyone can have the details of the diseases or the medicines. What if there is a place where you can find your health problem just by entering symptoms or just scanning an ECG or you can check whether the prescribed medicine is supposed to be used the way you are told to. Then it will help us to deduce the problem and to verify the solution. The proposed idea is to create a system with artificial intelligence that can meet the requirements. The AI can predict the diseases based on the symptoms and give the list of available treatments. The System can also give the composition of the medicines and their prescribed uses. It helps them to take the correct treatment. Hence the people can have an idea about their health and can have the right protection.},
author = {Ajayakumar, D Madhu; C J N Jain; E Sebastain; S Shaji; A},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/Papers/Maadu, Jain et al.pdf:pdf},
isbn = {9781509052974},
journal = {2017 International Conference on Inventive Communication and Computational Technologies (ICICCT)},
keywords = {ai,artificilal intelligence,chatbot,prediction},
number = {Icicct},
pages = {243},
title = {{A novel approach for medical assistance using trained chatbot}},
year = {2017}
}
@article{Elmasri2012,
abstract = {See, stats, and : http : / / www . researchgate . net / publication / 262288467 Detecting emotive CONFERENCE DOI : 10 . 1007 / 978 - 3 - 642 - 35139 - 6{\_}17 CITATIONS 2 READS 327 2 , INCLUDING : Rafael University 71 SEE Available : Rafael Retrieved : 23 Abstract . The study of emotions in human - computer interaction has increased in recent years in an attempt to address new user needs . At the same time , it is possible to record brain activity in real - time and discover patterns to relate it to emotional states . This paper describes a machine learning approach to detect emotion from brain activity , recorded as elec - troencephalograph (EEG) with the Emotic Epoc device , during auditory stimulation . First , we extract features from the EEG signals in order to characterize states of mind in the arousal - valence 2D emotion model . Us - ing these features we apply machine learning techniques to classify EEG signals into high / low arousal and positive / negative valence emotional states . The obtained classifiers may be used to categorize emotions such as happiness , anger , sadness , and calm based on EEG data .},
author = {Elmasri, Danielle and Maeder, Anthony},
doi = {10.1007/978-3-642-35139-6},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/10.1007-978-3-319-47103-7{\_}24.pdf:pdf},
isbn = {978-3-642-35138-9},
issn = {0302-9743},
pages = {243--251},
title = {{Brain Informatics}},
url = {http://link.springer.com/10.1007/978-3-642-35139-6},
volume = {7670},
year = {2012}
}
@article{Khosrow-pour2015,
abstract = {Our objective is to discuss the development of digital curation in cultural expression applications, such as museum and art gallery, focusing on the user experience's perspective. The use of digital technology has improved the production process in conventional museum and art gallery and has greatly facilitated the interaction between viewers and collections. Although the concept of digital museum has attracted a lot of attention recently, there remain many challenges to be addressed. Here, we discuss current progress in the development of digital museum and identify important factors that affect its successful deployment.},
author = {Khosrow-pour, Mehdi and Johnston, Lindsay and Yoder, Jennifer and Henning, Christina and Demarco, Austin and Travers, Jan and Brehm, Mike and Crodian, John and Gonzalez, Lisandro and Zombro, Deanna and Mull, Jason},
doi = {10.4018/978-1-4666-5888-2},
isbn = {9781466658882},
title = {{Encyclopedia of Information Science and Technology, Third Edition}},
url = {http://services.igi-global.com/resolvedoi/resolve.aspx?doi=10.4018/978-1-4666-5888-2},
volume = {II},
year = {2015}
}
@book{Roush2005,
abstract = {The editor in chief of Technology Review, like many executives, , engineers, and students these days, The -networking sites, in fact, were only a preview of what technologies will make possible.},
author = {Roush, Wade},
booktitle = {Technology},
doi = {10.1007/978-1-4842-1156-4},
isbn = {978-1-4842-1157-1},
issn = {1099274X},
number = {August},
pages = {1--18},
title = {{Social Machines}},
url = {http://www.technologyreview.com/Infotech/14664/page1/},
volume = {August, 20},
year = {2005}
}
@article{Cahn2017,
abstract = {Chatbots are “online human-computer dialog system[s] with natural language.” [1] The first conceptualization of the chatbot is attributed to Alan Turing, who asked “Can machines think?” in 1950. [3] Since Turing, chatbot technology has improved with advances in natural language processing and machine learning. Likewise, chatbot adoption has also increased, especially with the launch of chatbot platforms by Facebook [93], Kik [94], Slack [95], Skype [96], WeChat [97], Line [98], and Telegram [99]. By September 2016, Facebook Messenger hosted 30,000 bots and had 34,000 developers on its platform. [100] The Kik Bot Shop announced in August 2016 that the 20,000 bots created on its platform had “exchanged over 1.8 million messages.” [101] This paper is a literature review of the design choices, architecture, and algorithms used in chatbots. Section 1 will describe chatbot function and history in more detail and discuss the methods used to evaluate chatbots. Section 2, will walk through chatbot functionality step-by-step, beginning with automatic speech recognition (ASR) algorithms, natural language processing (NLP) functionality, response generation approaches, knowledge base creation strategies, and dialogue management (DM) algorithms, and concluding with a discussion of text to speech algorithms. Section 3 will focus on chatbot development, beginning with a case study of IBM Watson's chatbot functionality and concluding with a discussion of security considerations and chatbot applications.},
author = {Cahn, Jack},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/Papers/Chatbots/Cahn.pdf:pdf},
pages = {46},
title = {{CHATBOT: Architecture, Design, and Development}},
url = {https://static1.squarespace.com/static/569293741c1210fdda37b429/t/59160b6bff7c50104e601a85/1494616940469/CHATBOT{\_}thesis{\_}final.pdf},
year = {2017}
}
@article{Boushey2011,
author = {Boushey, Carol J},
doi = {10.1016/j.jada.2009.10.010.Evidence-based},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/Papers/Six, Schap et al.pdf:pdf},
journal = {Review Literature And Arts Of The Americas},
number = {1},
pages = {74--79},
title = {{NIH Public Access}},
volume = {110},
year = {2011}
}
@article{Milani2017,
abstract = {Health care consumers are taking control of their health information and desire a greater role in managing their health. Approximately 77{\%} of Americans now own a smartphone and the use of health apps have doubled over the past two years. These effects are particularly notable in patients with chronic disease, now representing half the adult population and responsible for 86{\%} of United States health care (HC) costs and 70{\%} of deaths. New opportunities exist as a result of recent advances in home-based wireless devices, apps, wearables, and interactive systems enabling health delivery systems to monitor, advise and treat disease near real time and engage patients in healthy living medicine. These technologies will provide a new framework for patient engagement and care delivery that will enhance clinical outcomes and generate precision interventions that ultimately reduce HC costs.},
author = {Milani, Richard V. and Franklin, Nina C.},
doi = {10.1016/j.pcad.2017.02.001},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/1-s2.0-S003306201730021X-main.pdf:pdf},
issn = {18731740},
journal = {Progress in Cardiovascular Diseases},
keywords = {Apps,Chronic disease,Wearables},
number = {5},
pages = {487--491},
pmid = {28189614},
publisher = {Elsevier Inc.},
title = {{The Role of Technology in Healthy Living Medicine}},
url = {http://dx.doi.org/10.1016/j.pcad.2017.02.001},
volume = {59},
year = {2017}
}
@article{Myers2015a,
abstract = {We present a system which can recognize the contents of your meal from a single image, and then predict its nu- tritional contents, such as calories. The simplest version assumes that the user is eating at a restaurant for which we know the menu. In this case, we can collect images offline to train a multi-label classifier. At run time, we apply the classifier (running on your phone) to predict which foods are present in your meal, and we lookup the corresponding nutritional facts. We apply this method to a new dataset of images from 23 different restaurants, using a CNN-based classifier, significantly outperforming previous work. The more challenging setting works outside of restaurants. In this case, we need to estimate the size of the foods, as well as their labels. This requires solving segmentation and depth / volume estimation from a single image. We present CNN-based approaches to these problems, with promising preliminary results. 1.},
author = {Myers, Austin and Johnston, Nick and Rathod, Vivek and Korattikara, Anoop and Gorban, Alex and Silberman, Nathan and Guadarrama, Sergio and Papandreou, George and Huang, Jonathan and Murphy, Kevin},
doi = {10.1109/ICCV.2015.146},
isbn = {9781467383912},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
number = {December},
pages = {1233--1241},
title = {{Im2Calories: Towards an automated mobile vision food diary}},
volume = {2015 Inter},
year = {2015}
}
@book{Pietro2016,
author = {Pietro, Giuseppe De and Howlett, Robert J},
doi = {10.1007/978-3-319-39345-2},
isbn = {978-3-319-39344-5},
title = {{Intelligent Interactive Multimedia Systems and Services 2016}},
url = {http://link.springer.com/10.1007/978-3-319-39345-2},
volume = {55},
year = {2016}
}
@article{Patil2017,
abstract = {{\textless}p{\textgreater}Before chatbots there were simply bots: The invention of a chatbot brought us to the new era of technology, the era of conversation service. A chatbot is a virtual person that can effectively talk to any human being with the help of interactive conversion textual skill. Now a days there are many cloud-based platforms available for developing and deploying the chatbot such as Microsoft bot framework, IBM Watson, Kore, AWS lambda, Microsoft Azure bot service, Chatfuel, Heroku and many more but all those techniques has some drawbacks such as built-in Artificial Intelligence, NLP, conversion service, programming etc. This paper represents the comparison between all cloud-based chatbot technologies with some constraint such as built-in AI, setup time, completion time, complexity etc. Finally, by the comparison, we will get to know that which cloud platform is efficient and suitable for developing chatbot.{\textless}/p{\textgreater}},
author = {Patil, Amit and K, Marimuthu and A, Nagaraja Rao and R, Niranchana and R, Niranchana},
doi = {10.14419/ijet.v6i3.7628},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/Papers/Chatbots/Patil, Marimuthu et al.pdf:pdf},
issn = {2227-524X},
journal = {International Journal of Engineering {\&} Technology},
keywords = {Artificial Intelligence,Chatbot techniques,Cloud Platform,NLP etc.},
number = {3},
pages = {57},
title = {{Comparative study of cloud platforms to develop a Chatbot}},
url = {https://www.sciencepubco.com/index.php/ijet/article/view/7628},
volume = {6},
year = {2017}
}
@article{Randolph2009,
abstract = {Writing a faulty literature review is one of many ways to derail a dissertation. This article summarizes some pivotal information on how to write a high-quality dissertation literature review. It begins with a discussion of the purposes of a review, presents taxonomy of literature reviews, and then discusses the steps in conducting a quantitative or qualitative literature review. The article concludes with a discussion of common mistakes and a framework for the self-evaluation of a literature review.},
archivePrefix = {arXiv},
arxivId = {arXiv:1403.5723v1},
author = {Randolph, Justus J},
doi = {10.1306/D426958A-2B26-11D7-8648000102C1865D},
eprint = {arXiv:1403.5723v1},
isbn = {1531-7714},
issn = {15317714},
journal = {Practical Assessment, Research {\&} Evaluation},
keywords = {Literature Reviews, Doctoral Dissertations, Statis},
number = {13},
pages = {1--13},
pmid = {1},
title = {{A Guide to Writing the Dissertation Literature Review}},
volume = {14},
year = {2009}
}
@article{Awwalu2015,
author = {Awwalu, Jamilu and {Garba Garba}, Ali and Ghazvini, A Anita and Atuah, Rose},
doi = {10.7763/IJCTE.2015.V7.999},
issn = {17938201},
journal = {International Journal of Computer Theory and Engineering},
number = {6},
pages = {439--443},
title = {{Artificial Intelligence in Personalized Medicine$\backslash$r$\backslash$nApplication of AI Algorithms in Solving Personalized $\backslash$r$\backslash$nMedicine Problems$\backslash$r$\backslash$n}},
volume = {7},
year = {2015}
}
@article{Ly2013,
abstract = {NONE},
author = {Ly, Kim and Zhao, Min and Soman, Dilip},
doi = {Research Report Series Behavioural Economics in Action},
isbn = {9781933820224},
issn = {1556-5068},
journal = {Rothman School of Management: University of Toronto},
pages = {1--28},
title = {{A Practitioner's Guide to Nudging}},
year = {2013}
}
@article{Kowatsch2017,
author = {Kowatsch, Tobias and Volland, Dirk and Shih, Iris and Dominik, R and Florian, K and Barata, Filipe and Filler, Andreas and Dirk, B and Heldt, Katrin and Gindrat, Pauline},
doi = {10.1007/978-3-319-59144-5},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/10.1007-978-3-319-59144-5{\_}36.pdf:pdf},
isbn = {978-3-319-59143-8},
pages = {485--489},
title = {{Designing the Digital Transformation}},
url = {http://link.springer.com/10.1007/978-3-319-59144-5},
volume = {10243},
year = {2017}
}
@article{Souza2017,
author = {Souza, Marcos and Miyagawa, Taynah and Melo, Paulo},
doi = {10.1007/978-3-319-58753-0},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/10.1007-978-3-319-58753-0{\_}44.pdf:pdf},
isbn = {978-3-319-58752-3},
keywords = {wellness,{\'{a}} habit,{\'{a}} wearable {\'{a}} health},
pages = {293--300},
title = {{HCI International 2017 – Posters' Extended Abstracts}},
url = {http://link.springer.com/10.1007/978-3-319-58753-0},
volume = {714},
year = {2017}
}
@article{Gabrielli2017,
author = {Gabrielli, Silvia and Create-net, F B K and Gabrielli, Silvia},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/PervasiveHealth{\_}Bot.pdf:pdf},
number = {July},
title = {{Addressing Challenges in Promoting Healthy Lifestyles : The AI-Chatbot Approach Addressing Challenges in Promoting Healthy Lifestyles : The AI-Chatbot Approach}},
year = {2017}
}
@article{Li2016,
abstract = {We demonstrate a video chatbot, which can generate human-level emotional comments referring to the videos shared by users and trigger a conversation with users. Our video chatbot performs a large-scale similar video search to find visually similar videos w.r.t. a given video using approximate nearest-neighbor search. Then, the comments associated with the searched similar videos are ranked by learning a deep multi-view embedding space for modeling video content, visual sentiment and textual comments. The top ranked comments are selected as responses to the given video and trigger the succeeding text-based chat between users and the chatbot. The demonstration is conducted on a newly collected dataset with over 102K videos and 10.6M comments. Moreover, our video chatbot has great potential to increase live social interactions.},
author = {Li, Yehao and Yao, Ting and Hu, Rui and Mei, Tao and Rui, Yong},
doi = {10.1145/2964284.2973835},
isbn = {9781450336031},
journal = {Proceedings of the 2016 ACM on Multimedia Conference},
keywords = {deep convolutional neural networks,lutional neural networks,multi-view embedding,video chatbot,video commenting},
pages = {757--758},
title = {{Video ChatBot : Triggering Live Social Interactions by Automatic Video Commenting}},
year = {2016}
}
@article{Cameron,
abstract = {The aim of this paper is to outline the design of a chatbot to be used within mental health counselling. One of the main causes of the burden of disease worldwide is mental health problems. Mental health contributes to 28{\%} of the total burden of disease, compared to 16{\%} each for cancer and heart disease in the UK. Stress, anxiety or depression accounted for 15.8 million days of sickness absence across the UK in 2016. By 2020, the gap between the demand for mental health care and the resources the National Health Service (NHS) can provide is likely to widen, therefore providers are increasingly needing to find more cost-effective ways to deliver mental health care. Digital Interventions have been created to help with these issues, for example anxiety, stress and depression. Chatbots can be incorporated into digital interventions, or used as standalone interventions. Chatbots can be a more interactive experience for the user to receive information, or complete diagnostic tools, or to even be used for counselling. A demo chatbot was created using interactive emoji's and GIFs to improve the user experience when searching for online self-help tips. This chatbot will be further developed and incorporated into a full web based programme for mental health in the workplace. It is envisaged that the chatbot will be able to provide initial counselling, and lead users into the correct services or self-help information.},
author = {Cameron, Gillian and Cameron, David and Megaw, Gavin and Bond, Raymond and Mulvenna, Maurice and Neill, Siobhan O ' and Armour, Cherie and Mctear, Michael},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/BHCI{\_}2017{\_}paper{\_}110.pdf:pdf},
journal = {Mental Health Artificial Intelligence},
pages = {1--7},
title = {{Towards a chatbot for digital counselling}},
url = {http://hci2017.bcs.org/wp-content/uploads/BHCI{\_}2017{\_}paper{\_}110.pdf}
}
@article{Gregori,
abstract = {This paper is a survey of modern chatbot platforms, Natural Language Processing tools, and their application and design. A chatbot is proposed for the GA Tech. OMSCS program to answer prospective students questions immediately 24/7.},
author = {Gregori, Eric},
file = {:Users/Lorenzo/Library/Application Support/Mendeley Desktop/Downloaded/Gregori - Unknown - Evaluation of Modern Tools for an OMSCS Advisor Chatbot.pdf:pdf},
journal = {School of Computer Science Graduate Student Publications, Georgia Tech},
title = {{Evaluation of Modern Tools for an OMSCS Advisor Chatbot}},
url = {https://smartech.gatech.edu/bitstream/handle/1853/58516/evaluation{\_}of{\_}modern{\_}tools{\_}for{\_}an{\_}omscs{\_}advisor{\_}chatbot{\%}281{\%}29.pdf?sequence=1{\&}isAllowed=y},
year = {2017}
}
@article{Ishida2017,
author = {Ishida, Yoshiteru and Chiba, Ryunosuke},
doi = {10.1016/j.procs.2017.08.190},
file = {:Users/Lorenzo/OneDrive - University of Edinburgh/MInf Project/Papers/Chatbots/Ishida, Chiba.pdf:pdf},
issn = {1877-0509},
journal = {Procedia Computer Science},
keywords = {Chatbots,Turing test,artificial consciousness,epsilon-delta definition,free will,matching,mutual recognition model},
pages = {2506--2518},
publisher = {Elsevier B.V.},
title = {{ScienceDirect ScienceDirect ScienceDirect Free Will and Turing Test with Multiple Agents : Free Will and Turing Test with Multiple Agents : An Example of Chatbot Design An Example of Chatbot Design}},
url = {http://dx.doi.org/10.1016/j.procs.2017.08.190},
volume = {112},
year = {2017}
}
